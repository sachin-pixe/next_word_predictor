# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qv9Rm37D63dAZXLRzXmWdpw92lXu4FDu
"""

import gradio as gr
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load tokenizer and model
model = load_model("word_predictor_model.h5")
with open("tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

max_sequence_len = 150  # same as in training

def generate_text(seed_text, next_words=5):
    for _ in range(next_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')
        predicted = model.predict(token_list, verbose=0)
        predicted_class = np.argmax(predicted)
        output_word = ""
        for word, index in tokenizer.word_index.items():
            if index == predicted_class:
                output_word = word
                break
        seed_text += " " + output_word
    return seed_text

iface = gr.Interface(fn=generate_text,
                     inputs=["text", gr.Slider(1, 20, value=5, label="Words to Predict")],
                     outputs="text",
                     title="ðŸ§  LSTM Word Predictor",
                     description="Enter a seed text and watch the model continue it!")

iface.launch()

!pip install gradio

